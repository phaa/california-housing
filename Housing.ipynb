{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02da73f2-e82c-430a-85f5-005c71ea5211",
   "metadata": {},
   "source": [
    "# Baixando arquivos do github e e extraindo em um arquivo csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ea8496-6fdd-4f77-b585-651bf21bcc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    # Cria a pasta datasets/housing\n",
    "    os.makedirs(housing_path, exist_ok=True)\n",
    "\n",
    "    # Cria um caminho absoluto para o arquivo .tgz\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "\n",
    "    # Baixa o arquivo .tgz e joga no caminho criado\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "\n",
    "    # Abre o arquivo, extrai para datasets/housing e depois fecha ele\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path, filter=\"data\")\n",
    "    housing_tgz.close()\n",
    "\n",
    "fetch_housing_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378c32a4-2e12-40e0-b139-0a7f5c2882c5",
   "metadata": {},
   "source": [
    "# Carregando dados em um dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c779ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando dados\n",
    "import pandas as pd\n",
    "\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "housing = load_housing_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4bd37e",
   "metadata": {},
   "source": [
    "# Obtendo detalhes do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2511afdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # Obtendo uma rápida descricao dos dados\n",
    "housing.info()\n",
    "\n",
    "# Descobrindo a contagem de cada tipo de dado na coluna ocean_proximity\n",
    "housing[\"ocean_proximity\"]\n",
    "\n",
    "# Dá um resumo dos atributos numéricos do dataframe\n",
    "housing.describe() \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf7f2bd",
   "metadata": {},
   "source": [
    "# Plotando os dados usando gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a1bfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" %matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "housing.hist(bins=50, figsize=(20,15)) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7df310",
   "metadata": {},
   "source": [
    "# Criando um conjunto de testes (método 1)\n",
    "Esse método é menos complexo, porém, toda vez que executarmos o programa, ele selecionará elementos diferentes (random).\\\n",
    "Em pouco tempo, todos os elementos de teste, passarao pelo conjunto de treinamento. E nao queremos isso!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b9a2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import numpy as np\n",
    "\n",
    "def split_train_test(data, test_ratio):\n",
    "    # Retorna um array de inteiros de 0 até len(data)\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "\n",
    "    # Calcula a quantidade de elementos que farao parte do conjunto de teste\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "\n",
    "    # Pega as posicoes dos elementos de teste como sendo do array embaralhado do inicio até test_set_size\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "\n",
    "    # Pega as posicoes dos elementos de treinamento como sendo de test_set_size até o fim do array embaralhado\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "\n",
    "    # dataframe.iloc voce pode passar tambem um array de indices e ele retornara um dataframe mostrando aqueles elementos\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]\n",
    "\n",
    "# Geralmente para treinamento se utiliza 20% do conjunto total\n",
    "train_set, test_set = split_train_test(housing, 0.2)\n",
    "\n",
    "print(len(train_set))\n",
    "\n",
    "print(len(test_set))\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f49317",
   "metadata": {},
   "source": [
    "# Criando um conjunto de testes (método 2)\n",
    "Esse método consiste em calcular o hash do identificador de cada instancia e verificar se é menor que 20% do valor máximo dele.\\\n",
    "Assim, o conjunto de testes consistente em todas as execucoes do programa, mesmo que sejam adicionadas instancias novas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047cf772",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import numpy as np\n",
    "from zlib import crc32\n",
    "\n",
    "def test_set_check(identifier, test_ratio):\n",
    "    return crc32(np.int64(identifier)) & 0xffffffff < test_ratio * (2 ** 32)\n",
    "\n",
    "def split_train_set_by_id(data, test_ratio, id_column):\n",
    "    # Pega uma series contendo os ids de cada entrada \n",
    "    ids = data[id_column]\n",
    "\n",
    "    # apply() recebe uma funcao para aplicar a cada elemento do conjunto dem ids\n",
    "    is_in_test_set = ids.apply(lambda id: test_set_check(id, test_ratio))\n",
    "\n",
    "    # dataframe.loc[] serve para retornar as colunas como series. Se usar .loc[['col1', 'col2']] retorna um dataframe\n",
    "    # se passar um array de boolean (array.length == len(dataframe)) para o .loc[], ele retorna o elemento i caso array[i] == True\n",
    "    # o til (~) antes do array is_in_test_set serve para negar elemento por elemento, ou seja, se array = [True, True, False], logo ~array[False, False, True]\n",
    "    # testar com iloc depois\n",
    "    return data.loc[~is_in_test_set], data.loc[is_in_test_set]\n",
    "\n",
    "# Esse conjunto de dados nao tem uma coluna de ID, logo vamos improvisar uma:\n",
    "housing_with_id = housing.reset_index() # adiciona um index a coluna\n",
    "train_set, test_set = split_train_set_by_id(housing, 0.2, \"index\")\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4aca31",
   "metadata": {},
   "source": [
    "# Criando um conjunto de testes (método 3)\n",
    "Esse método utiliza o método train_test_split do sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8fc881",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # Basicamente esse método faz o que implmentamos manualmente no método 2\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42) # 42 é o numero da sorte :)\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd72e444",
   "metadata": {},
   "source": [
    "# Adicionando uma categoria com estratos\n",
    "Vamos adicionar uma nova categoria ao dataframe a partir da estratificacao da renda media.\\\n",
    "Se voce quiser fazer uma pesquisa representando a populacao dos EUA (51,3% M, 48,7% H) voce deve seguir a mesma proporcao ao tomar um conjunto de pesquisa.\\\n",
    "Da mesma forma fazemos ao tomar um conjunto de testes e treinamento. Assim evitamos o *viés de amostagem*.\\\n",
    "Nesse caso, a categoria Homem é um estrato, e Mulher outro.\\\n",
    "Da mesma maneira, vamos criar estratos baseados na renda média."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1c76e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# O método cut subdivide uma coluna em grupos menores de acordo com a configuracao\n",
    "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"], # a partir de qual coluna\n",
    "                               bins=[0., 1.5, 3.0, 4.5, 6, np.inf], # subdivisao que vemos quando plotamos a coluna\n",
    "                               labels=[1, 2, 3, 4, 5]) # qual a categoria\n",
    "\n",
    "#housing[\"income_cat\"].hist()\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def stratified_split():\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42) # n_splits = numero de divisoes\n",
    "\n",
    "    # como nesse caso n_splits=1 na primeira iteracao ja podemos retornar os conjuntos na primeira iteracao\n",
    "    for train_indices, test_indices in split.split(housing, housing[\"income_cat\"]):\n",
    "        strat_train_set = housing.loc[train_indices]\n",
    "        strat_test_set = housing.loc[test_indices]\n",
    "\n",
    "        print(strat_train_set.info())\n",
    "\n",
    "        # Agora que já separamos os dados em categorias, podemos remover a coluna income_cat\n",
    "        strat_train_set.drop(\"income_cat\", axis=1, inplace=True)\n",
    "        strat_test_set.drop(\"income_cat\", axis=1, inplace=True)\n",
    "\n",
    "        #print(strat_test_set[\"income_cat\"].value_counts() / len(strat_test_set))\n",
    "        return strat_train_set, strat_test_set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15f0884",
   "metadata": {},
   "source": [
    "# Redefinindo o conjunto de estudos\n",
    "A partir de agora vamos assumir que housing é apenas o conjunto de treinamento.\\\n",
    "Já que ele está corretamente estratificado, a amostragem será identica ao de todo o conjunto.\\\n",
    "Fazemos isso para evitar de trabalhar com o conjunto de testes.\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5ccc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set, strat_test_set = stratified_split()\n",
    "housing = strat_train_set.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1878b6",
   "metadata": {},
   "source": [
    "# Visualizando os dados geográficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2581a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\n",
    "             s=housing[\"population\"]/100, label=\"population\", figsize=(10,7),\n",
    "             c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b56b27",
   "metadata": {},
   "source": [
    "# Buscando correlacoes\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
